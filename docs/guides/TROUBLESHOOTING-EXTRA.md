# üîß Troubleshooting - Guia Completo de Solu√ß√µes

**√öltima atualiza√ß√£o:** 15/11/2025
**Vers√£o:** 1.0.0

---

## üìã √çndice

1. [Erros de Deploy (CI/CD)](#erros-de-deploy-cicd)
2. [Erros de CORS](#erros-de-cors)
3. [Erros de Autentica√ß√£o](#erros-de-autentica√ß√£o)
4. [Erros de Tenant](#erros-de-tenant)
5. [Erros de Docker](#erros-de-docker)
6. [Erros de Banco de Dados](#erros-de-banco-de-dados)
7. [Erros de Build/TypeScript](#erros-de-buildtypescript)
8. [Erros de Rate Limiting](#erros-de-rate-limiting)
9. [Erros de Nginx](#erros-de-nginx)
10. [Problemas de Performance](#problemas-de-performance)

---

## üöÄ Erros de Deploy (CI/CD)

### Erro: "Invalid SSH key format"

**Sintoma:**
```
::error::Invalid SSH key format. Please check VPS_SSH_KEY secret.
```

**Causa:**
- Secret `VPS_SSH_KEY` com formato incorreto
- Chave corrompida ou incompleta

**Solu√ß√£o:**

```bash
# 1. Verificar formato da chave local
cat ~/.ssh/id_rsa | head -1
# Deve come√ßar com: -----BEGIN OPENSSH PRIVATE KEY-----
# ou: -----BEGIN RSA PRIVATE KEY-----

# 2. Gerar nova chave se necess√°rio
ssh-keygen -t rsa -b 4096 -m PEM -C "github-actions" -f ~/.ssh/github_deploy

# 3. Copiar chave p√∫blica para VPS
ssh-copy-id -i ~/.ssh/github_deploy.pub root@72.61.39.235

# 4. Testar conex√£o
ssh -i ~/.ssh/github_deploy root@72.61.39.235 "echo 'SSH OK'"

# 5. Atualizar secret no GitHub
cat ~/.ssh/github_deploy
# Copiar TODO o conte√∫do (incluindo BEGIN e END)
# Colar em: GitHub ‚Üí Settings ‚Üí Secrets ‚Üí VPS_SSH_KEY

# Op√ß√£o: Usar base64 (mais seguro)
cat ~/.ssh/github_deploy | base64 -w 0
# Colar o base64 no secret
```

### Erro: "VPS does not respond to ping"

**Sintoma:**
```
::warning::VPS does not respond to ping (ICMP may be blocked by firewall)
```

**Causa:**
- VPS tem firewall bloqueando ICMP
- Comportamento normal em servidores hardened

**Solu√ß√£o:**
- ‚úÖ **IGNORAR** - √â apenas um warning informativo
- O workflow continua e testa SSH (que √© o cr√≠tico)
- Se SSH funciona, est√° tudo OK

**Se quiser habilitar ping (opcional):**
```bash
ssh root@72.61.39.235

# Habilitar ICMP no firewall (ufw)
ufw allow icmp

# Ou iptables
iptables -A INPUT -p icmp -j ACCEPT
```

### Erro: "Disk usage is above 90%"

**Sintoma:**
```
::error::Disk usage is above 90%. Aborting deployment.
```

**Causa:**
- Disco cheio na VPS
- Logs, backups ou imagens Docker ocupando espa√ßo

**Solu√ß√£o:**

```bash
ssh root@72.61.39.235

# 1. Ver uso de disco
df -h
du -sh /* | sort -h

# 2. Limpar Docker (CUIDADO!)
docker system prune -a --volumes
# Pergunta confirma√ß√£o - digite 'y'

# 3. Limpar backups antigos
cd /root/deploy-backend/backups
ls -lth
rm -rf pre-deploy-20251110-*  # Exemplo: deletar backups antigos

# 4. Limpar imagens Docker de backup antigas
docker images | grep backup
docker rmi deploy-backend_backend:backup-20251110-120000

# 5. Limpar logs do sistema
journalctl --vacuum-time=7d

# 6. Verificar novamente
df -h
```

### Erro: "Docker is not running"

**Sintoma:**
```
::error::Docker is not running
```

**Causa:**
- Docker daemon parado
- Docker n√£o instalado
- Permiss√µes incorretas

**Solu√ß√£o:**

```bash
ssh root@72.61.39.235

# 1. Verificar status
systemctl status docker

# 2. Iniciar Docker
systemctl start docker

# 3. Habilitar auto-start
systemctl enable docker

# 4. Verificar
docker ps
docker info

# Se Docker n√£o est√° instalado:
curl -fsSL https://get.docker.com -o get-docker.sh
sh get-docker.sh
```

### Erro: "Health check failed after 30 attempts"

**Sintoma:**
```
::error::Health check failed after 30 attempts
Backend logs (last 50 lines):
[logs do container]
```

**Causa:**
- Backend n√£o inicializa corretamente
- Erro na aplica√ß√£o Node.js
- Banco de dados n√£o conecta
- Porta 3001 n√£o responde

**Solu√ß√£o:**

```bash
ssh root@72.61.39.235
cd /root/deploy-backend

# 1. Ver logs completos
docker logs crm-backend --tail 200

# 2. Verificar status do container
docker ps -a | grep crm-backend

# 3. Verificar health
docker inspect crm-backend | grep -A 10 Health

# 4. Testar health endpoint diretamente
docker exec crm-backend curl http://localhost:3001/api/health

# 5. Verificar conectividade com PostgreSQL
docker exec crm-backend node -e "const {PrismaClient} = require('@prisma/client'); const p = new PrismaClient(); p.\$connect().then(() => console.log('DB OK')).catch(e => console.error('DB ERROR:', e));"

# 6. Verificar conectividade com Redis
docker exec crm-backend node -e "const Redis = require('ioredis'); const r = new Redis({host: 'redis'}); r.ping().then(() => console.log('Redis OK')).catch(e => console.error('Redis ERROR:', e));"

# 7. Restart completo
docker compose -f docker-compose.production.yml restart postgres redis
sleep 10
docker compose -f docker-compose.production.yml restart backend

# 8. Se nada funcionar, rebuild
docker compose -f docker-compose.production.yml down
docker compose -f docker-compose.production.yml up -d --build
```

### Erro: "Failed to run migrations"

**Sintoma:**
```
::error::Failed to run migrations
```

**Causa:**
- PostgreSQL n√£o est√° pronto
- Migration com erro SQL
- Permiss√µes de banco de dados

**Solu√ß√£o:**

```bash
ssh root@72.61.39.235
cd /root/deploy-backend

# 1. Verificar PostgreSQL
docker logs crm-postgres --tail 50
docker exec crm-postgres pg_isready -U crm_user

# 2. Testar conex√£o
docker exec crm-postgres psql -U crm_user -d crm_whatsapp_saas -c "SELECT NOW();"

# 3. Ver status das migrations
docker exec crm-backend npx prisma migrate status

# 4. Aplicar migrations manualmente
docker exec crm-backend npx prisma migrate deploy

# 5. Se migration espec√≠fica falha, ver logs
docker exec crm-backend npx prisma migrate status --schema=./prisma/schema.prisma

# 6. Rollback de migration (√∫ltimo recurso)
docker exec crm-backend npx prisma migrate resolve --rolled-back 20251115000000_migration_name
```

---

## üåê Erros de CORS

### Erro: "No 'Access-Control-Allow-Origin' header"

**Sintoma (browser console):**
```
Access to XMLHttpRequest at 'https://api.botreserva.com.br/auth/login'
from origin 'https://www.botreserva.com.br' has been blocked by CORS policy:
No 'Access-Control-Allow-Origin' header is present on the requested resource.
```

**Causa:**
- Origem n√£o est√° em `FRONTEND_URL`
- `.env` n√£o atualizado
- Container n√£o foi recriado ap√≥s mudar `.env`

**Solu√ß√£o:**

```bash
ssh root@72.61.39.235
cd /root/deploy-backend

# 1. Verificar FRONTEND_URL atual
cat .env | grep FRONTEND_URL

# 2. Ver o que est√° no container
docker exec crm-backend printenv FRONTEND_URL

# 3. Atualizar .env (N√ÉO .env.production)
# M√∫ltiplas URLs separadas por v√≠rgula
vim .env
# Adicionar: FRONTEND_URL=https://url1,https://url2,https://url3

# Ou usar sed:
sed -i "s|^FRONTEND_URL=.*|FRONTEND_URL=https://projeto-eva-frontend.vercel.app,https://www.botreserva.com.br,https://botreserva.com.br|" .env

# 4. CR√çTICO: Usar --force-recreate (n√£o apenas restart)
docker compose -f docker-compose.production.yml up -d --force-recreate backend

# 5. Verificar se atualizou
docker exec crm-backend printenv FRONTEND_URL
# Deve exibir: https://projeto-eva-frontend.vercel.app,https://www.botreserva.com.br,https://botreserva.com.br

# 6. Testar CORS
curl -I -X OPTIONS "https://api.botreserva.com.br/auth/login" \
  -H "Origin: https://www.botreserva.com.br" \
  -H "Access-Control-Request-Method: POST" \
  -H "Access-Control-Request-Headers: content-type"

# Resposta esperada:
# HTTP/2 204
# access-control-allow-origin: https://www.botreserva.com.br
# access-control-allow-credentials: true
```

**Documenta√ß√£o:** Ver `docs/CORS-FIX-2025-11-15.md` para detalhes completos.

### Erro: CORS funciona em uma origem mas n√£o em outra

**Sintoma:**
- `https://www.botreserva.com.br` funciona
- `https://botreserva.com.br` (sem www) n√£o funciona

**Causa:**
- Faltou adicionar a origem sem www

**Solu√ß√£o:**

```bash
# Verificar FRONTEND_URL
docker exec crm-backend printenv FRONTEND_URL

# Deve ter TODAS as varia√ß√µes:
# - https://botreserva.com.br (sem www)
# - https://www.botreserva.com.br (com www)
# - https://projeto-eva-frontend.vercel.app (Vercel)

# Atualizar se necess√°rio
ssh root@72.61.39.235
cd /root/deploy-backend
vim .env
# Adicionar todas as URLs separadas por v√≠rgula (SEM espa√ßos extras)

docker compose -f docker-compose.production.yml up -d --force-recreate backend
```

---

## üîê Erros de Autentica√ß√£o

### Erro: "Email ou senha inv√°lidos"

**Sintoma (API response):**
```json
{
  "error": "Email ou senha inv√°lidos"
}
```

**Causa:**
- Senha incorreta
- Usu√°rio n√£o existe para esse tenant
- Hash bcrypt corrompido

**Solu√ß√£o:**

```bash
ssh root@72.61.39.235

# 1. Verificar se usu√°rio existe
docker exec crm-postgres psql -U crm_user -d crm_whatsapp_saas -c \
  "SELECT id, email, role, \"tenantId\" FROM users WHERE email = 'admin@example.com';"

# Se n√£o retornar nada, usu√°rio n√£o existe

# 2. Criar novo usu√°rio admin (se n√£o existir)
docker exec crm-backend node -e "
const {PrismaClient} = require('@prisma/client');
const bcrypt = require('bcrypt');
const prisma = new PrismaClient();

async function createAdmin() {
  const password = await bcrypt.hash('Admin123!Change', 10);
  const user = await prisma.user.create({
    data: {
      email: 'admin@example.com',
      password: password,
      name: 'Admin',
      role: 'SUPER_ADMIN',
      tenantId: null
    }
  });
  console.log('User created:', user.id);
}

createAdmin().catch(console.error).finally(() => prisma.\$disconnect());
"

# 3. Resetar senha de usu√°rio existente
docker exec crm-backend node -e "
const bcrypt = require('bcrypt');
bcrypt.hash('NovaSenha123!', 10).then(hash => {
  console.log('Hash:', hash);
  console.log('Use este hash no UPDATE abaixo');
});
"

# Copiar o hash e usar no UPDATE:
docker exec crm-postgres psql -U crm_user -d crm_whatsapp_saas -c \
  "UPDATE users SET password = '\$2b\$10\$HASH_AQUI' WHERE email = 'admin@example.com';"

# 4. Testar login via curl
curl -X POST https://api.botreserva.com.br/auth/login \
  -H "Content-Type: application/json" \
  -H "X-Tenant-Slug: super-admin" \
  -d '{"email":"admin@example.com","password":"Admin123!Change"}' \
  -v
```

### Erro: Frontend d√° erro e recarrega p√°gina (Vercel)

**Sintoma (Console do navegador):**
```
Fetch failed loading: GET "https://www.botreserva.com.br/.well-known/vercel/jwe"
Fetch failed loading: HEAD "https://www.botreserva.com.br/login"
```

**Quando acontece:**
- Usu√°rio tenta fazer login
- P√°gina recarrega rapidamente sem mostrar mensagem de erro
- Erros aparecem no console do navegador (F12)

**Causa poss√≠vel:**
1. Dom√≠nio customizado `www.botreserva.com.br` n√£o configurado corretamente na Vercel
2. Recursos da Vercel (`.well-known/vercel/jwe`) n√£o acess√≠veis
3. Configura√ß√£o de roteamento do Next.js pode estar faltando

**Solu√ß√£o (A INVESTIGAR):**

```bash
# 1. Verificar configura√ß√£o do dom√≠nio na Vercel
# Acessar: https://vercel.com/[seu-projeto]/settings/domains
# Confirmar:
# - www.botreserva.com.br est√° adicionado
# - SSL est√° ativo
# - DNS est√° configurado (CNAME para cname.vercel-dns.com)

# 2. Verificar se o dom√≠nio est√° respondendo
curl -I https://www.botreserva.com.br

# 3. Testar login diretamente pelo dom√≠nio Vercel
# Acessar: https://projeto-eva-frontend.vercel.app
# Tentar fazer login

# 4. Se funcionar no dom√≠nio Vercel mas n√£o no customizado:
# - Remover e re-adicionar dom√≠nio na Vercel
# - Aguardar propaga√ß√£o DNS (5-15 minutos)
# - Limpar cache do navegador (Ctrl+Shift+Del)

# 5. Verificar logs de build na Vercel
# https://vercel.com/[seu-projeto]/deployments
```

**Status:** ‚ö†Ô∏è **PENDENTE INVESTIGA√á√ÉO** (documentado em 15/11/2025)

**Pr√≥ximos passos:**
1. Testar login pelo dom√≠nio Vercel direto
2. Se funcionar, problema √© DNS/configura√ß√£o de dom√≠nio
3. Se n√£o funcionar, problema √© no c√≥digo/backend
4. Verificar logs do backend durante tentativa de login
5. Adicionar console.log no frontend para capturar erro completo

---

### Erro: "Unauthorized" ou "Invalid token"

**Sintoma:**
```json
{
  "error": "Unauthorized",
  "message": "Invalid token"
}
```

**Causa:**
- Token JWT expirado
- Token malformado
- Secret JWT mudou

**Solu√ß√£o:**

```bash
# 1. Fazer login novamente para obter novo token
curl -X POST https://api.botreserva.com.br/auth/login \
  -H "Content-Type: application/json" \
  -H "X-Tenant-Slug: tenant-slug" \
  -d '{"email":"seu@email.com","password":"suasenha"}'

# 2. Usar o token retornado no campo "access_token"
TOKEN="eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9..."

# 3. Testar endpoint protegido
curl https://api.botreserva.com.br/api/conversations \
  -H "Authorization: Bearer $TOKEN" \
  -H "X-Tenant-Slug: tenant-slug"

# 4. Se continuar dando erro, verificar JWT_SECRET
ssh root@72.61.39.235
cd /root/deploy-backend
cat .env | grep JWT_SECRET
# Deve ter pelo menos 32 caracteres

# 5. Se JWT_SECRET mudou recentemente, todos os tokens antigos s√£o inv√°lidos
# Usu√°rios precisam fazer login novamente
```

---

## üè¢ Erros de Tenant

### Erro: "Tenant not found"

**Sintoma:**
```json
{
  "error": "Tenant not found",
  "statusCode": 401
}
```

**Causa:**
- Header `X-Tenant-Slug` n√£o enviado
- Slug incorreto
- Tenant n√£o existe no banco

**Solu√ß√£o:**

```bash
ssh root@72.61.39.235

# 1. Ver todos os tenants no banco
docker exec crm-postgres psql -U crm_user -d crm_whatsapp_saas -c \
  "SELECT id, slug, name, status FROM tenants;"

# 2. Verificar se slug espec√≠fico existe
docker exec crm-postgres psql -U crm_user -d crm_whatsapp_saas -c \
  "SELECT id, slug, name FROM tenants WHERE slug = 'hotel-ipanema';"

# 3. Se n√£o existe, criar tenant
# Fazer login como SUPER_ADMIN primeiro:
TOKEN=$(curl -s -X POST https://api.botreserva.com.br/auth/login \
  -H "Content-Type: application/json" \
  -d '{"email":"admin@botreserva.com.br","password":"SUA_SENHA_SUPER_ADMIN"}' \
  | jq -r '.access_token')

# Criar tenant:
curl -X POST https://api.botreserva.com.br/api/tenants \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $TOKEN" \
  -d '{
    "name": "Hotel Ipanema",
    "slug": "hotel-ipanema",
    "email": "contato@hotelipanema.com",
    "adminName": "Admin",
    "adminEmail": "admin@hotelipanema.com",
    "adminPassword": "Senha123!"
  }'

# 4. Testar requisi√ß√£o com header correto
curl https://api.botreserva.com.br/api/conversations \
  -H "Content-Type: application/json" \
  -H "X-Tenant-Slug: hotel-ipanema" \
  -H "Authorization: Bearer $TOKEN"
```

### Erro: "Invalid tenant. Reserved subdomain cannot be used"

**Sintoma:**
```json
{
  "error": "Invalid tenant. Reserved subdomain cannot be used as tenant identifier."
}
```

**Causa:**
- Tentando usar subdom√≠nio reservado como tenant
- Exemplos: www, api, admin, app, mail, ftp

**Solu√ß√£o:**
- ‚úÖ **Usar header X-Tenant-Slug** ao inv√©s de subdom√≠nio
- ‚úÖ Escolher slug que n√£o seja reservado

```bash
# ‚ùå ERRADO - "www" √© reservado
curl https://www.botreserva.com.br/api/health
# Retorna erro "Invalid tenant"

# ‚úÖ CORRETO - Usar header
curl https://api.botreserva.com.br/api/health \
  -H "X-Tenant-Slug: hotel-ipanema"
```

**Lista de subdom√≠nios reservados:**
- www
- api
- admin
- app
- mail
- ftp
- localhost

**Documenta√ß√£o:** Ver `deploy-backend/src/middlewares/tenant.middleware.ts` linha 60.

---

## üê≥ Erros de Docker

### Erro: Container reiniciando constantemente

**Sintoma:**
```bash
docker ps
# crm-backend   Restarting (1) 5 seconds ago
```

**Causa:**
- Aplica√ß√£o crashando na inicializa√ß√£o
- Depend√™ncias (DB/Redis) n√£o prontas
- Erro de sintaxe no c√≥digo

**Solu√ß√£o:**

```bash
ssh root@72.61.39.235
cd /root/deploy-backend

# 1. Ver logs
docker logs crm-backend --tail 100 -f

# 2. Ver √∫ltimo erro antes do crash
docker logs crm-backend 2>&1 | grep -i error | tail -20

# 3. Verificar depend√™ncias
docker ps | grep -E "postgres|redis"
# Devem estar "healthy" ou "Up"

# 4. Testar PostgreSQL
docker exec crm-postgres pg_isready -U crm_user

# 5. Testar Redis
docker exec crm-redis redis-cli -a $(cat .env | grep REDIS_PASSWORD | cut -d'=' -f2) PING

# 6. Verificar health check
docker inspect crm-backend | grep -A 20 Health

# 7. Restart sequencial (DB primeiro, depois app)
docker compose -f docker-compose.production.yml restart postgres redis
sleep 10
docker compose -f docker-compose.production.yml restart backend

# 8. Se continuar crashando, rebuild
docker compose -f docker-compose.production.yml down
docker compose -f docker-compose.production.yml up -d --build
```

### Erro: "Error response from daemon: conflict"

**Sintoma:**
```
Error response from daemon: Conflict. The container name "/crm-backend" is already in use
```

**Causa:**
- Container antigo ainda existe (mesmo parado)

**Solu√ß√£o:**

```bash
# 1. Parar e remover container
docker stop crm-backend
docker rm crm-backend

# 2. Recriar
docker compose -f docker-compose.production.yml up -d backend

# Ou for√ßar recria√ß√£o:
docker compose -f docker-compose.production.yml up -d --force-recreate backend
```

### Erro: "No space left on device"

**Sintoma:**
```
Error: ENOSPC: no space left on device
```

**Causa:**
- Disco cheio

**Solu√ß√£o:**

```bash
# 1. Ver uso de disco
df -h

# 2. Limpar Docker
docker system df
docker system prune -a --volumes

# 3. Remover logs antigos
journalctl --vacuum-time=7d

# 4. Remover backups antigos
cd /root/deploy-backend/backups
ls -lh
rm -rf pre-deploy-202511*  # Exemplo

# 5. Ver o que est√° ocupando espa√ßo
du -sh /* | sort -h | tail -20
```

---

## üíæ Erros de Banco de Dados

### Erro: "Connection timeout" ou "ECONNREFUSED"

**Sintoma (logs):**
```
Error: connect ECONNREFUSED 127.0.0.1:5432
```

**Causa:**
- PostgreSQL n√£o est√° rodando
- Firewall bloqueando porta
- DATABASE_URL incorreto

**Solu√ß√£o:**

```bash
ssh root@72.61.39.235

# 1. Verificar se PostgreSQL est√° rodando
docker ps | grep postgres

# 2. Ver logs do PostgreSQL
docker logs crm-postgres --tail 50

# 3. Testar conex√£o
docker exec crm-postgres pg_isready -U crm_user

# 4. Verificar DATABASE_URL
docker exec crm-backend printenv DATABASE_URL
# Formato correto: postgresql://crm_user:PASSWORD@postgres:5432/crm_whatsapp_saas

# 5. Testar query manual
docker exec crm-postgres psql -U crm_user -d crm_whatsapp_saas -c "SELECT NOW();"

# 6. Restart PostgreSQL
cd /root/deploy-backend
docker compose -f docker-compose.production.yml restart postgres

# 7. Aguardar ficar pronto
sleep 5
docker exec crm-postgres pg_isready -U crm_user

# 8. Restart backend
docker compose -f docker-compose.production.yml restart backend
```

### Erro: "relation does not exist"

**Sintoma:**
```
Error: relation "users" does not exist
```

**Causa:**
- Migrations n√£o foram executadas
- Banco de dados vazio

**Solu√ß√£o:**

```bash
ssh root@72.61.39.235
cd /root/deploy-backend

# 1. Ver status das migrations
docker exec crm-backend npx prisma migrate status

# 2. Aplicar migrations pendentes
docker exec crm-backend npx prisma migrate deploy

# 3. Verificar tabelas criadas
docker exec crm-postgres psql -U crm_user -d crm_whatsapp_saas -c "\dt"

# 4. Se n√£o houver tabelas, resetar banco (CUIDADO!)
docker exec crm-backend npx prisma migrate reset --skip-seed
docker exec crm-backend npx prisma migrate deploy

# 5. Ver estrutura da tabela
docker exec crm-postgres psql -U crm_user -d crm_whatsapp_saas -c "\d users"
```

---

## üî® Erros de Build/TypeScript

### Erro: TypeScript compilation errors

**Sintoma (CI/CD logs):**
```
error TS2322: Type 'string | undefined' is not assignable to type 'string'
```

**Causa:**
- Erros de tipo no c√≥digo TypeScript
- Type assertions faltando

**Solu√ß√£o:**

```bash
# 1. Build local primeiro
cd deploy-backend
npm install
npm run build

# 2. Ver erros TypeScript
npx tsc --noEmit

# 3. Corrigir erros no c√≥digo
# Exemplo: Adicionar type assertion
# ANTES:
const tenantId = req.tenantId;

# DEPOIS:
const tenantId = req.tenantId as string;

# 4. Commit e push
git add .
git commit -m "fix: TypeScript errors - add type assertions"
git push

# Deploy autom√°tico vai rodar
```

### Erro: "Cannot find module '@/...'"

**Sintoma:**
```
Error: Cannot find module '@/config/database'
```

**Causa:**
- Path aliases n√£o resolvidos
- `tsc-alias` n√£o executado

**Solu√ß√£o:**

```bash
# 1. Verificar tsconfig.json
cat deploy-backend/tsconfig.json
# Deve ter:
# "baseUrl": "./src",
# "paths": {
#   "@/*": ["./*"]
# }

# 2. Verificar build script
cat deploy-backend/package.json
# Deve ter:
# "build": "tsc -p tsconfig.production.json && tsc-alias -p tsconfig.production.json"

# 3. Instalar tsc-alias se n√£o estiver
cd deploy-backend
npm install --save-dev tsc-alias

# 4. Rebuild
npm run build

# 5. Verificar dist/ gerado
ls -la dist/
cat dist/config/database.js  # Paths devem estar resolvidos
```

---

## ‚è±Ô∏è Erros de Rate Limiting

### Erro: "Too many login attempts"

**Sintoma:**
```
HTTP 429 Too Many Requests
{
  "error": "Too many login attempts, please try again later."
}
```

**Causa:**
- Rate limit atingido (padr√£o: 100 req/15min)
- IP bloqueado temporariamente

**Solu√ß√£o (para usu√°rio):**
```
Aguardar 15 minutos e tentar novamente
```

**Solu√ß√£o (para admin - aumentar limite):**

```bash
ssh root@72.61.39.235

# 1. Ver configura√ß√£o atual
docker exec crm-backend cat src/middlewares/rate-limit.middleware.ts | grep -A 5 "loginLimiter"

# 2. Editar c√≥digo (se necess√°rio aumentar limite)
vim deploy-backend/src/middlewares/rate-limit.middleware.ts

# Alterar:
max: 100,  // Para 200 ou mais

# 3. Commit, push e deploy
git add .
git commit -m "fix: aumentar rate limit para 200 req/15min"
git push

# 4. Limpar rate limit de um IP espec√≠fico (tempor√°rio)
docker exec crm-redis redis-cli -a $(cat /root/deploy-backend/.env | grep REDIS_PASSWORD | cut -d'=' -f2) \
  KEYS "*rate-limit*" | xargs docker exec crm-redis redis-cli -a PASSWORD DEL
```

**Documenta√ß√£o:** Ver commit `ee38b3f` para fix aplicado.

---

## üåê Erros de Nginx

### Erro: "502 Bad Gateway"

**Sintoma (browser):**
```
502 Bad Gateway
nginx/1.24.0
```

**Causa:**
- Backend n√£o est√° respondendo
- Backend crashou
- Porta 3001 n√£o acess√≠vel

**Solu√ß√£o:**

```bash
ssh root@72.61.39.235

# 1. Verificar backend
docker ps | grep crm-backend
docker logs crm-backend --tail 50

# 2. Testar backend diretamente
docker exec crm-backend curl http://localhost:3001/api/health

# 3. Verificar Nginx config
docker exec crm-nginx nginx -t

# 4. Ver logs Nginx
docker logs crm-nginx --tail 50

# 5. Restart backend
cd /root/deploy-backend
docker compose -f docker-compose.production.yml restart backend

# 6. Restart Nginx
docker compose -f docker-compose.production.yml restart nginx

# 7. Testar novamente
curl https://api.botreserva.com.br/api/health
```

### Erro: "504 Gateway Timeout"

**Sintoma:**
```
504 Gateway Timeout
```

**Causa:**
- Requisi√ß√£o demorou mais de 60s (timeout padr√£o do Nginx)

**Solu√ß√£o:**

```bash
ssh root@72.61.39.235

# 1. Ver logs do backend (o que est√° travando?)
docker logs crm-backend --tail 100

# 2. Aumentar timeout do Nginx (se necess√°rio)
vim /root/deploy-backend/nginx/conf.d/api.conf

# Adicionar/aumentar:
proxy_read_timeout 120s;
proxy_connect_timeout 120s;
proxy_send_timeout 120s;

# 3. Recarregar Nginx
docker exec crm-nginx nginx -s reload

# Ou restart:
docker compose -f docker-compose.production.yml restart nginx
```

---

## üöÄ Problemas de Performance

### Problema: API lenta

**Sintoma:**
- Requisi√ß√µes demorando mais de 2s

**Investiga√ß√£o:**

```bash
ssh root@72.61.39.235

# 1. Ver uso de CPU/Mem√≥ria
docker stats --no-stream

# 2. Ver queries lentas no banco
docker exec crm-postgres psql -U crm_user -d crm_whatsapp_saas -c \
  "SELECT query, calls, mean_exec_time FROM pg_stat_statements ORDER BY mean_exec_time DESC LIMIT 10;"

# 3. Ver logs do backend para slow queries
docker logs crm-backend 2>&1 | grep -i "slow"

# 4. Verificar se Redis est√° sendo usado
docker exec crm-redis redis-cli -a PASSWORD INFO stats
# Ver: keyspace_hits e keyspace_misses
```

**Solu√ß√µes:**

```bash
# 1. Adicionar indexes no banco
# Ver schema.prisma e adicionar @@index

# 2. Implementar cache Redis
# Ver src/config/redis.ts

# 3. Aumentar resources do container
vim /root/deploy-backend/docker-compose.production.yml

# Adicionar em backend:
deploy:
  resources:
    limits:
      cpus: '2.0'
      memory: 2G

# Restart:
docker compose -f docker-compose.production.yml up -d backend
```

### Problema: Banco de dados lento

**Sintoma:**
- Queries demorando muito

**Solu√ß√£o:**

```bash
ssh root@72.61.39.235

# 1. Analisar queries
docker exec crm-postgres psql -U crm_user -d crm_whatsapp_saas -c \
  "EXPLAIN ANALYZE SELECT * FROM conversations WHERE \"tenantId\" = 'uuid-here';"

# 2. Ver tabelas sem index
docker exec crm-postgres psql -U crm_user -d crm_whatsapp_saas -c \
  "SELECT schemaname, tablename, indexname FROM pg_indexes WHERE schemaname = 'public';"

# 3. Vacuum/Analyze
docker exec crm-postgres psql -U crm_user -d crm_whatsapp_saas -c "VACUUM ANALYZE;"

# 4. Aumentar mem√≥ria do PostgreSQL
vim /root/deploy-backend/docker-compose.production.yml

# Adicionar em postgres:
command: postgres -c shared_buffers=256MB -c max_connections=100

# Restart:
docker compose -f docker-compose.production.yml restart postgres
```

---

## üìû Suporte

### Logs √öteis

```bash
# Todos os logs
docker compose -f docker-compose.production.yml logs -f

# Apenas backend
docker logs crm-backend -f

# Apenas erros
docker logs crm-backend 2>&1 | grep -i error

# √öltimas 100 linhas
docker logs crm-backend --tail 100
```

### Comandos de Diagn√≥stico

```bash
# Status de todos os containers
docker ps -a

# Health de todos
docker ps --format "table {{.Names}}\t{{.Status}}"

# Uso de recursos
docker stats --no-stream

# Espa√ßo em disco
df -h
docker system df

# Conectividade
curl -I https://api.botreserva.com.br/api/health
```

---

## üìö Documentos Relacionados

- [DEPLOY-PRODUCTION.md](./DEPLOY-PRODUCTION.md) - Guia de deploy
- [CORS-FIX-2025-11-15.md](./CORS-FIX-2025-11-15.md) - Fix CORS
- [DOCUMENTACAO-COMPLETA.md](./DOCUMENTACAO-COMPLETA.md) - Documenta√ß√£o t√©cnica
- [GUIA-META-WHATSAPP-API.md](./GUIA-META-WHATSAPP-API.md) - WhatsApp

---

**√öltima atualiza√ß√£o:** 15/11/2025
**Commits relacionados:**
- `ee38b3f` - Rate limiting fix
- `88ac470` - Tenant middleware (www)
- `3fc0216` - CORS m√∫ltiplas origens
- `bd04c30` - Ping check opcional
- `9650645` - Docker Compose v2
- `ed5757b` - SSH key format fix
